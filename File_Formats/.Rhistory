})
})
d = dat[dat$id == "205-517", ]
mods = ddply(dat, .(id), function(d){
mx = max(d$from_base)
my = d$truevol[ which(d$from_base == mx) ]
knots = unique(d$from_base)
# take out last one - otherwise unstable
knots = knots[ knots!= mx]
mod = lm(truevol ~ -1 + bs(x = from_base, degree = 1,
knots = knots),
data=d)
suppressWarnings({p = predict(mod, pred.df)})
p = cbind(pred.df, truevol = p)
p$truevol[ p$from_base > mx ] = my
p
}, .progress = 'text')
m = mods[mods$id == "205-517", ]
# plot(truevol ~ from_base, data=d, type='p')
# points(truevol ~ from_base, data=m, xlim=range(d$from_base))
#
# mods = ddply(dat, .(id), function(d){
#   mx = max(d$from_base)
#   my = d$truevol[ which(mx == max(d$from_base)) ]
#   mod = smooth.spline(y=d$truevol, x=d$from_base, all.knots = TRUE)
#   p = predict(mod, pred.df$from_base)$y
#   p = cbind(pred.df, truevol = p)
#   p$truevol[ p$from_base > mx ] = my
#   p
# }, .progress = 'text')
# g %+% mods
mat = spread(mods, key=id, value=truevol)
mat$from_base = NULL
mat = as.matrix(mat)
pca = prcomp(x = mat, center=TRUE, scale=TRUE)
spca = summary(pca)
pct.var = spca$importance['Cumulative Proportion',]
cutoff = 0.95
keep = which(pct.var <= cutoff)
pcs = pca$x[, keep]
cormat = cor(pcs, mat)
plot.ind = apply(cormat, 1, which.max)
plot.ids = colnames(mat)[plot.ind]
n.id = length(unique(dat$id))
dat$id = factor(dat$id)
g = qplot(x=from_base, y = truevol, colour = id, data=dat, geom="line") +
guides(colour=FALSE)
col = rep(alpha("black", 0.1), n.id)
col[ levels(dat$id) %in% plot.ids ] = alpha("black", 1)
g = g + scale_colour_manual(values = col) + theme_bw()
g
rm(list=ls())
library(plyr)
library(dplyr)
library(mgcv)
library(ggplot2)
library(splines)
library(tidyr)
library(scales)
datadir = "~/Dropbox/CTR/DHanley/CT_Registration/Final_Brain_Seg/results/"
load(file.path(datadir, "ICC_data.Rda"))
dat = ddf[, c("id", "from_base", "truevol")]
#############
# Only days <= 10 days psot baseline
#############
dat$from_base = as.numeric(dat$from_base)
dat = dat %>% subset(!is.na(from_base)) %>% subset(from_base <= 10)
counts = ddply(dat, .(id), summarise, N = n())
dat = merge(dat, counts, sort=FALSE)
dat = dat %>% subset(N > 3)
# getting range of data and prediction matrix
ranges = dat %$% from_base %>% range %>% as.numeric
pred.df = data.frame(from_base = seq(ranges[1], ranges[2], by=0.01))
#############
# Creating interpolation models
#############
# mods = ddply(dat, .(id), function(d){
#   mod = gam(formula = truevol ~ s(from_base, k=8), data=d, method="REML")
#   p = predict(mod, newdata = pred.df)
#   p = cbind(pred.df, truevol = p)
#   p
# }, .progress = 'text')
dat = ddply(dat, .(id), function(d){
d = ddply(d, .(from_base), function(x){
x = x[1,]
})
})
d = dat[dat$id == "205-517", ]
mods = ddply(dat, .(id), function(d){
mx = max(d$from_base)
my = d$truevol[ which(d$from_base == mx) ]
knots = unique(d$from_base)
# take out last one - otherwise unstable
knots = knots[ knots!= mx]
mod = lm(truevol ~ -1 + bs(x = from_base, degree = 1,
knots = knots),
data=d)
suppressWarnings({p = predict(mod, pred.df)})
p = cbind(pred.df, truevol = p)
p$truevol[ p$from_base > mx ] = my
p
}, .progress = 'text')
m = mods[mods$id == "205-517", ]
# plot(truevol ~ from_base, data=d, type='p')
# points(truevol ~ from_base, data=m, xlim=range(d$from_base))
#
# mods = ddply(dat, .(id), function(d){
#   mx = max(d$from_base)
#   my = d$truevol[ which(mx == max(d$from_base)) ]
#   mod = smooth.spline(y=d$truevol, x=d$from_base, all.knots = TRUE)
#   p = predict(mod, pred.df$from_base)$y
#   p = cbind(pred.df, truevol = p)
#   p$truevol[ p$from_base > mx ] = my
#   p
# }, .progress = 'text')
# g %+% mods
mat = spread(mods, key=id, value=truevol)
mat$from_base = NULL
mat = as.matrix(mat)
pca = prcomp(x = mat, center=TRUE, scale=TRUE)
spca = summary(pca)
pct.var = spca$importance['Cumulative Proportion',]
cutoff = 0.95
keep = which(pct.var <= cutoff)
pcs = pca$x[, keep]
cormat = cor(pcs, mat)
plot.ind = apply(cormat, 1, which.max)
plot.ids = colnames(mat)[plot.ind]
n.id = length(unique(dat$id))
dat$id = factor(dat$id)
g = qplot(x=from_base, y = truevol, colour = id, data=dat, geom="line") +
guides(colour=FALSE)
col = rep(alpha("black", 0.2), n.id)
col[ levels(dat$id) %in% plot.ids ] = alpha("black", 1)
g = g + scale_colour_manual(values = col) + theme_bw()
g
g = qplot(x=from_base, y = truevol, colour = id, data=dat, geom="line") +
guides(colour=FALSE)
g
col = rep(alpha("black", 0.2), n.id)
col[ levels(dat$id) %in% plot.ids ] = alpha("black", 1)
g = g + scale_colour_manual(values = col) + theme_bw()
g
?prcomp
pca2 = prcomp(x = t(mat), center=TRUE, scale=TRUE)
pca2
dim(pca2$x)
dim(pca$x)
plot(pca$x[,1])
plot(pred.df$from_base, pca$x[,1])
eq(ranges[1], ranges[2], by=0.01))
#############
# Creating interpolation models
#############
# mods = ddply(dat, .(id), function(d){
#   mod = gam(formula = truevol ~ s(from_base, k=8), data=d, method="REML")
#   p = predict(mod, newdata = pred.df)
#   p = cbind(pred.df, truevol = p)
#   p
# }, .progress = 'text')
dat = ddply(dat, .(id), function(d){
d = ddply(d, .(from_base), function(x){
x = x[1,]
})
})
d = dat[dat$id == "205-517", ]
mods = ddply(dat, .(id), function(d){
mx = max(d$from_base)
my = d$truevol[ which(d$from_base == mx) ]
knots = unique(d$from_base)
# take out last one - otherwise unstable
knots = knots[ knots!= mx]
mod = lm(truevol ~ -1 + bs(x = from_base, degree = 1,
knots = knots),
data=d)
suppressWarnings({p = predict(mod, pred.df)})
p = cbind(pred.df, truevol = p)
p$truevol[ p$from_base > mx ] = my
p
}, .progress = 'text')
m = mods[mods$id == "205-517", ]
# plot(truevol ~ from_base, data=d, type='p')
# points(truevol ~ from_base, data=m, xlim=range(d$from_base))
#
# mods = ddply(dat, .(id), function(d){
#   mx = max(d$from_base)
#   my = d$truevol[ which(mx == max(d$from_base)) ]
#   mod = smooth.spline(y=d$truevol, x=d$from_base, all.knots = TRUE)
#   p = predict(mod, pred.df$from_base)$y
#   p = cbind(pred.df, truevol = p)
#   p$truevol[ p$from_base > mx ] = my
#   p
# }, .progress = 'text')
# g %+% mods
mat = spread(mods, key=id, value=truevol)
mat$from_base = NULL
mat = as.matrix(mat)
pca = prcomp(x = mat, center=TRUE, scale=TRUE)
spca = summary(pca)
pct.var = spca$importance['Cumulative Proportion',]
cutoff = 0.95
keep = which(pct.var <= cutoff)
pcs = pca$x[, keep]
cormat = cor(pcs, mat)
plot.ind = apply(cormat, 1, which.max)
plot.ids = colnames(mat)[plot.ind]
n.id = length(unique(dat$id))
dat$id = factor(dat$id)
g = qplot(x=from_base, y = truevol, colour = id, data=dat, geom="line") +
guides(colour=FALSE)
col = rep(alpha("black", 0.2), n.id)
col[ levels(dat$id) %in% plot.ids ] = alpha("black", 1)
g = g + scale_colour_manual(values = col) + theme_bw()
g
rm(list=ls())
library(plyr)
library(dplyr)
library(mgcv)
library(ggplot2)
library(splines)
library(tidyr)
library(scales)
datadir = "~/Dropbox/CTR/DHanley/CT_Registration/Final_Brain_Seg/results/"
load(file.path(datadir, "ICC_data.Rda"))
dat = ddf[, c("id", "from_base", "truevol")]
#############
# Only days <= 10 days psot baseline
#############
dat$from_base = as.numeric(dat$from_base)
dat = dat %>% subset(!is.na(from_base)) %>% subset(from_base <= 10)
counts = ddply(dat, .(id), summarise, N = n())
dat = merge(dat, counts, sort=FALSE)
dat = dat %>% subset(N > 3)
# getting range of data and prediction matrix
ranges = dat %$% from_base %>% range %>% as.numeric
pred.df = data.frame(from_base = seq(ranges[1], ranges[2], by=0.01))
#############
# Creating interpolation models
#############
# mods = ddply(dat, .(id), function(d){
#   mod = gam(formula = truevol ~ s(from_base, k=8), data=d, method="REML")
#   p = predict(mod, newdata = pred.df)
#   p = cbind(pred.df, truevol = p)
#   p
# }, .progress = 'text')
dat = ddply(dat, .(id), function(d){
d = ddply(d, .(from_base), function(x){
x = x[1,]
})
})
d = dat[dat$id == "205-517", ]
mods = ddply(dat, .(id), function(d){
mx = max(d$from_base)
my = d$truevol[ which(d$from_base == mx) ]
knots = unique(d$from_base)
# take out last one - otherwise unstable
knots = knots[ knots!= mx]
mod = lm(truevol ~ -1 + bs(x = from_base, degree = 1,
knots = knots),
data=d)
suppressWarnings({p = predict(mod, pred.df)})
p = cbind(pred.df, truevol = p)
p$truevol[ p$from_base > mx ] = my
p
}, .progress = 'text')
m = mods[mods$id == "205-517", ]
# plot(truevol ~ from_base, data=d, type='p')
# points(truevol ~ from_base, data=m, xlim=range(d$from_base))
#
# mods = ddply(dat, .(id), function(d){
#   mx = max(d$from_base)
#   my = d$truevol[ which(mx == max(d$from_base)) ]
#   mod = smooth.spline(y=d$truevol, x=d$from_base, all.knots = TRUE)
#   p = predict(mod, pred.df$from_base)$y
#   p = cbind(pred.df, truevol = p)
#   p$truevol[ p$from_base > mx ] = my
#   p
# }, .progress = 'text')
# g %+% mods
mat = spread(mods, key=id, value=truevol)
mat$from_base = NULL
mat = as.matrix(mat)
pca = prcomp(x = mat, center=TRUE, scale=TRUE)
spca = summary(pca)
pct.var = spca$importance['Cumulative Proportion',]
cutoff = 0.95
keep = which(pct.var <= cutoff)
pcs = pca$x[, keep]
cormat = cor(pcs, mat)
plot.ind = apply(cormat, 1, which.max)
plot.ids = colnames(mat)[plot.ind]
n.id = length(unique(dat$id))
dat$id = factor(dat$id)
g = qplot(x=from_base, y = truevol, colour = id, data=dat, geom="line") +
guides(colour=FALSE)
col = rep(alpha("black", 0.2), n.id)
col[ levels(dat$id) %in% plot.ids ] = alpha("black", 1)
g = g + scale_colour_manual(values = col) + theme_bw()
g
#
# mods = ddply(dat, .(id), function(d){
#   gam(formula = truevol ~ from_base, data=d)
# }, .progress = 'text')
rm(list=ls())
library(plyr)
library(dplyr)
library(mgcv)
library(ggplot2)
library(splines)
library(tidyr)
library(scales)
macs <- read.table("http://faculty.washington.edu/heagerty/Courses/VA-longitudinal/private/MACS-cd4-vload0.raw")
datadir = "~/Dropbox/CTR/DHanley/CT_Registration/Final_Brain_Seg/results/"
load(file.path(datadir, "ICC_data.Rda"))
dat = ddf[, c("id", "from_base", "truevol")]
#############
# Only days <= 10 days psot baseline
#############
dat$from_base = as.numeric(dat$from_base)
dat = dat %>% subset(!is.na(from_base)) %>% subset(from_base <= 10)
counts = ddply(dat, .(id), summarise, N = n())
dat = merge(dat, counts, sort=FALSE)
dat = dat %>% subset(N > 3)
# getting range of data and prediction matrix
ranges = dat %$% from_base %>% range %>% as.numeric
pred.df = data.frame(from_base = seq(ranges[1], ranges[2], by=0.01))
#############
# Creating interpolation models
#############
# mods = ddply(dat, .(id), function(d){
#   mod = gam(formula = truevol ~ s(from_base, k=8), data=d, method="REML")
#   p = predict(mod, newdata = pred.df)
#   p = cbind(pred.df, truevol = p)
#   p
# }, .progress = 'text')
dat = ddply(dat, .(id), function(d){
d = ddply(d, .(from_base), function(x){
x = x[1,]
})
})
d = dat[dat$id == "205-517", ]
mods = ddply(dat, .(id), function(d){
mx = max(d$from_base)
my = d$truevol[ which(d$from_base == mx) ]
knots = unique(d$from_base)
# take out last one - otherwise unstable
knots = knots[ knots!= mx]
mod = lm(truevol ~ -1 + bs(x = from_base, degree = 1,
knots = knots),
data=d)
suppressWarnings({p = predict(mod, pred.df)})
p = cbind(pred.df, truevol = p)
p$truevol[ p$from_base > mx ] = my
p
}, .progress = 'text')
m = mods[mods$id == "205-517", ]
# plot(truevol ~ from_base, data=d, type='p')
# points(truevol ~ from_base, data=m, xlim=range(d$from_base))
#
# mods = ddply(dat, .(id), function(d){
#   mx = max(d$from_base)
#   my = d$truevol[ which(mx == max(d$from_base)) ]
#   mod = smooth.spline(y=d$truevol, x=d$from_base, all.knots = TRUE)
#   p = predict(mod, pred.df$from_base)$y
#   p = cbind(pred.df, truevol = p)
#   p$truevol[ p$from_base > mx ] = my
#   p
# }, .progress = 'text')
# g %+% mods
mat = spread(mods, key=id, value=truevol)
mat$from_base = NULL
mat = as.matrix(mat)
pca = prcomp(x = mat, center=TRUE, scale=TRUE)
spca = summary(pca)
pct.var = spca$importance['Cumulative Proportion',]
cutoff = 0.95
keep = which(pct.var <= cutoff)
pcs = pca$x[, keep]
cormat = cor(pcs, mat)
plot.ind = apply(cormat, 1, which.max)
plot.ids = colnames(mat)[plot.ind]
n.id = length(unique(dat$id))
dat$id = factor(dat$id)
g = qplot(x=from_base, y = truevol, colour = id, data=dat, geom="line") +
guides(colour=FALSE)
col = rep(alpha("black", 0.2), n.id)
col[ levels(dat$id) %in% plot.ids ] = alpha("black", 1)
g = g + scale_colour_manual(values = col) + theme_bw()
g
#
# mods = ddply(dat, .(id), function(d){
#   gam(formula = truevol ~ from_base, data=d)
# }, .progress = 'text')
rm(list=ls())
library(plyr)
library(dplyr)
library(mgcv)
library(ggplot2)
library(splines)
library(tidyr)
library(scales)
# ID = subject ID
# MONTHS = months since seroconversion (detection of infection)
# AGE = age of subject
# CD4-COUNT = # of CD4 positive cells (helper cells) per mm^3
#   CD8-COUNT = # of CD8 positive cells (supressor cells) per mm^3
#   VLOAD0 = viral load at baseline (copies per ml)
# AIDSCASE = 1 if no AIDS observed; 2 if AIDS observed; 3 if died prior to AIDS
# VTIME = calendar time of study visit in months since January 1984
# SCTIME = calendar time of seroconversion (infection) in months since 1/1984
# ATIME = calendar time of AIDS diagnosis in months since 1/1984
# DTIME = calendar time of death in months since 1/1984, or follow-up time
# IDEATH = indicator of death at DTIME (1=death, 0=censored)
macs <- read.table("http://faculty.washington.edu/heagerty/Courses/VA-longitudinal/private/MACS-cd4-vload0.raw")
colnames(macs) = c("id", "age", "cd4", "cd8", "vload", "aids",
"vtime", "sctime", "atime", "dtime", "ideath")
dat = macs
######################################
# Should it be a PCA on the residuals from Y ~ X or from the de-meaned and scaled data?
####################################
idvar = "id"
yvar = "cd4"
xvar=  "age"
gridsize = 0.01
dat = dat[, c(idvar, yvar, xvar)]
colnames(dat) = c("id", "y", "x")
dat$id = factor(dat$id)
g = qplot(x=x, y = y, colour = id, data=dat, geom="line") +
guides(colour=FALSE)
g
counts = ddply(dat, .(id), summarise, N = n())
dat = merge(dat, counts, sort=FALSE)
dat = dat %>% subset(N > 3)
# getting range of data and prediction matrix
ranges = dat %$% x %>% range %>% as.numeric
pred.df = data.frame(x = seq(ranges[1], ranges[2], by=gridsize))
#############
# Creating interpolation models
#############
# dat = ddply(dat, .(id), function(d){
#   d = ddply(d, .(x), function(x){
#     x = x[1,]
#   })
# })
mods = ddply(dat, .(id), function(d){
mx = max(d$x)
my = d$truevol[ which(d$x == mx) ]
knots = unique(d$x)
# take out last one - otherwise unstable
knots = knots[ knots!= mx]
mod = lm(y ~ -1 + bs(x = x, degree = 1,
knots = knots),
data=d)
suppressWarnings({p = predict(mod, pred.df)})
p = cbind(pred.df, y = p)
p$y[ p$from_base > mx ] = my
p
}, .progress = 'text')
# plot(truevol ~ from_base, data=d, type='p')
# points(truevol ~ from_base, data=m, xlim=range(d$from_base))
#
# mods = ddply(dat, .(id), function(d){
#   mx = max(d$from_base)
#   my = d$truevol[ which(mx == max(d$from_base)) ]
#   mod = smooth.spline(y=d$truevol, x=d$from_base, all.knots = TRUE)
#   p = predict(mod, pred.df$from_base)$y
#   p = cbind(pred.df, truevol = p)
#   p$truevol[ p$from_base > mx ] = my
#   p
# }, .progress = 'text')
# g %+% mods
mat = spread(mods, key=id, value=y)
mat$x = NULL
mat = as.matrix(mat)
pca = prcomp(x = mat, center=TRUE, scale=TRUE)
spca = summary(pca)
pct.var = spca$importance['Cumulative Proportion',]
cutoff = 0.95
keep = seq(1, max(1, min(which(pct.var > cutoff) - 1)))
pcs = pca$x[, keep, drop=FALSE]
cormat = cor(pcs, mat)
plot.ind = apply(cormat, 1, which.max)
plot.ids = colnames(mat)[plot.ind]
pred.df$mean = rowMeans(mat)
n.id = length(unique(dat$id))
dat$id = factor(dat$id)
g = qplot(x=x, y = y, colour = id, size = id, data=dat, geom="line") +
guides(colour=FALSE, size = FALSE)
col = rep(alpha("black", 0.1), n.id)
lwd = rep(1, n.id)
col[ levels(dat$id) %in% plot.ids ] = alpha("black", 1)
lwd[ levels(dat$id) %in% plot.ids ] = 2
g = g + scale_colour_manual(values = col) + scale_size_manual(values = lwd) +
theme_bw()
g2 = g + geom_smooth(aes(group=1), se=FALSE, colour= "green", size = 2)
g2
library(knitr)
library(highr)
opts_chunk$set(echo=TRUE, prompt=FALSE, message=FALSE, warning=FALSE, comment="", dev='png')
knit_hooks$set(inline = function(x) {
if (is.numeric(x)) return(knitr:::format_sci(x, 'latex'))
hi_latex(x)
})
setwd("~/Dropbox/Neurohacking/File_Formats")
library(oro.dicom)
slice = readDICOM('Example_DICOM.dcm')
class(slice)
all_slices = readDICOM('T1/')
class(all_slices)
?dicom2nifti
nii = dicom2nifti(all_slices)
dim(nii)
